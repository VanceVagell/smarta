This file describes changes made to SMARTA before the initial Git commit, to help explain some of its design and functionality decisions.

SMARTA was designed and tested with the lemurs at Duke Lemur Center from May 2015 to March 2017. We made changes along the way to troubleshoot or enhance SMARTA’s capabilities and features. During our initial training process, we realized that glare under natural (outdoor) conditions was problematic; we therefore conducted all training and testing indoors to eliminate glare on the touchscreen component of the SMARTA. Realizing we were unable to tell how many food rewards were dispensed or whether we correctly tapped the “dispense” button, we integrated a food count button and haptic feedback on the phone app during training. During testing, the smartphone does not vibrate nor does it show a food count because SMARTA runs automatically. A reset option was added on the phone app to reset the conveyer belt to its original position if training or testing trial was started accidentally. Later, bigger “dispense” and “rewind” buttons on the smartphone screen were added to make it easier to tap during training. The drop down menu for selecting a lemur’s name was changed to a list on the home screen to make it easier for researchers to select.  A few days into data collection, we realized that we were unable to sort our data on Google Spreadsheet based on the date. Thus, we added a sortable time stamp into the app so data for both training and testing can be sorted by the date and time it was recorded. 

We also made multiple changes and improvements to SMARTA as we trained the lemurs. Initially, we thought that the target square on the touchscreen was not big enough to gain their attention so we made the square larger. Later, we realized that enlarging the target square did not help with the efficiency of training, so we reduced it back to the previous size. We soon learned that the lemurs are impatient and like to swipe around when being trained. The “Kiosk Mode” was enabled on the tablet, which suppresses the back button so lemurs do not accidentally hit the Home screen and get out of the SMARTA app. 

Multiple training options were then implemented so that the lemurs learn the testing sessions. First we added the option to show two squares where the presentation of red and grey are randomized (left or right) and the ability to animate the red square by making it wiggle. Then, we added the option to choose where the red and grey would appear during testing so that the presentation of red and grey squares are no longer randomized but can be manually selected via the phone app. Later, we redesigned the training and testing screens to make it easier for researchers to select buttons and to make the user interface more polished. At the end, eight options were added for training session to guide the lemurs from paying attention to the touchscreen, to targeting the red square, and lastly to learning the discrimination task by showing the lemurs two stimuli but only reinforcing the red target. Researchers are able to choose which option to use by tapping on the smartphone screen. 

As training progressed, almost all of the lemurs had figured out shortcuts to get the food reward. Some lemurs were observed swiping their hand all over the screen, putting their hand in the middle of the two squares, or putting their hand on one side of the screen. We spent a few more weeks correcting and shaping the lemur’s behaviour by positively reinforcing the lemurs with a whistle bridge so that they pay attention to the screen as well as shaping them to wait and make a choice only when the squares are present on the screen. Most lemurs at Duke Lemur Center were whistle trained, so adding a whistle bridge to the training did not impede the time needed to train the animals. Because of the effectiveness of a whistle bridge during training, we also incorporated whistle sound during testing to continuously reinforce this behaviour. Since SMARTA runs automatically during testing, it plays a whistle sound when dispensing food rewards to bridge the correct choice and food reward. The whistle sound was programmed using the sound of the actual whistle used during training.

The SMARTA software was updated for testing so that a choice is only registered when a lemur chooses one side of the screen, and that when two squares are touched simultaneously the software ignores the input. Rather than using the default Android touch handling (e.g., listening for touch events on each square), SMARTA has custom touch handling logic. We found that normal touch handling was imprecise when lemurs dragged their hands across the screen, sometimes triggering long press events or other unpredictable behaviour. To ensure consistent results, we use the Android method “handleTouch(MotionEvent)” attached to the background container that fills the entire touchscreen. The method “handleTouch(MotionEvent)” registers any touch or movement of a finger anywhere on the screen, and evaluates the precise position of each finger to determine if it’s within the bounds of a square, and whether that square is “correct” or “incorrect” for the current trial. If any finger was in a square, the trial ends and “correct” or “incorrect” is recorded. Lastly, after our validation study, SMARTA was updated to record trial durations in milliseconds instead of seconds to make the latency of testing duration more accurate. 
